{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Case Study 2</h1></center>\n",
    "<center><h3> Week 2 (out of 5)</h3></center>\n",
    "\n",
    "**Author(s):**\n",
    "1. Robin Fu (robin.fu@emory.edu)\n",
    " \n",
    "**Data Source**: W.C. Hunter and M.B. Walker (1996), [“*The Cultural Affinity Hypothesis and Mortgage Lending Decisions*,”](https://link.springer.com/article/10.1007/BF00174551) Journal of Real Estate Finance and Economics 13, 57-70.\n",
    " \n",
    "**Book**: [Introductory Econometrics: A Modern Approach](https://economics.ut.ac.ir/documents/3030266/14100645/Jeffrey_M._Wooldridge_Introductory_Econometrics_A_Modern_Approach__2012.pdf) by Jeffrey Wooldridge\n",
    "\n",
    "**Data Description**: ```http://fmwww.bc.edu/ec-p/data/wooldridge/loanapp.dta```\n",
    "\n",
    "```\n",
    "  Obs:  1989\n",
    "\n",
    "  1. occ                       occupancy\n",
    "  2. loanamt                   loan amt in thousands\n",
    "  3. action                    type of action taken\n",
    "  4. msa                       msa number of property\n",
    "  5. suffolk                   =1 if property in Suffolk County\n",
    "  6. race                      race of applicant\n",
    "  7. gender                    gender of applicant\n",
    "  8. appinc                    applicant income, $1000s\n",
    "  9. typur                     type of purchaser of loan\n",
    " 10. unit                      number of units in property\n",
    " 11. married                   =1 if applicant married\n",
    " 12. dep                       number of dependents\n",
    " 13. emp                       years employed in line of work\n",
    " 14. yjob                      years at this job\n",
    " 15. self                      self-employment dummy\n",
    " 16. atotinc                   total monthly income\n",
    " 17. cototinc                  coapp total monthly income\n",
    " 18. hexp                      propose housing expense\n",
    " 19. price                     purchase price\n",
    " 20. other                     other financing, $1000s\n",
    " 21. liq                       liquid assets\n",
    " 22. rep                       no. of credit reports\n",
    " 23. gdlin                     credit history meets guidelines\n",
    " 24. lines                     no. of credit lines on reports\n",
    " 25. mortg                     credit history on mortgage paym\n",
    " 26. cons                      credit history on consumer stuf\n",
    " 27. pubrec                    =1 if filed bankruptcy\n",
    " 28. hrat                      housing exp, % total inccome\n",
    " 29. obrat                     other oblgs,  % total income\n",
    " 30. fixadj                    fixed or adjustable rate?\n",
    " 31. term                      term of loan in months\n",
    " 32. apr                       appraised value\n",
    " 33. prop                      type of property\n",
    " 34. inss                      PMI sought\n",
    " 35. inson                     PMI approved\n",
    " 36. gift                      gift as down payment\n",
    " 37. cosign                    is there a cosigner\n",
    " 38. unver                     unverifiable info\n",
    " 39. review                    number of times reviewed\n",
    " 40. netw                      net worth\n",
    " 41. unem                      unemployment rate by industry\n",
    " 42. min30                     =1 if minority pop. > 30%\n",
    " 43. bd                        =1 if boarded-up val > MSA med\n",
    " 44. mi                        =1 if tract inc > MSA median\n",
    " 45. old                       =1 if applic age > MSA median\n",
    " 46. vr                        =1 if tract vac rte > MSA med\n",
    " 47. sch                       =1 if > 12 years schooling\n",
    " 48. black                     =1 if applicant black\n",
    " 49. hispan                    =1 if applicant Hispanic\n",
    " 50. male                      =1 if applicant male\n",
    " 51. reject                    =1 if action == 3\n",
    " 52. approve                   =1 if action == 1 or 2\n",
    " 53. mortno                    no mortgage history\n",
    " 54. mortperf                  no late mort. payments\n",
    " 55. mortlat1                  one or two late payments\n",
    " 56. mortlat2                  > 2 late payments\n",
    " 57. chist                     =0 if accnts deliq. >= 60 days\n",
    " 58. multi                     =1 if two or more units\n",
    " 59. loanprc                   amt/price\n",
    " 60. thick                     =1 if rep > 2\n",
    " 61. white                     =1 if applicant white\n",
    " 62. obwhte                    obrat*awhite\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [5 points] After loading the data set into a Pandas DataFrame, use the approaches described [here](https://stackoverflow.com/questions/50326157/create-dummy-variables-for-interdependent-categories-in-pandas]) to create dummies for the interdependent race categories `black`, `hispan`, `white` and gender category `male`. **Hint:** You should have generated a total of 6 new dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Turning off pandas and numpy warnings\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "np.seterr(all = 'ignore')\n",
    "\n",
    "#Loading data and dropping NA rows, esp for male column\n",
    "df = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/loanapp.dta')\n",
    "df = df.dropna()\n",
    "\n",
    "#Creating 6 dummy variables by race and gender\n",
    "dummies = pd.get_dummies(df.race.astype(str) + df.male.astype(str))\n",
    "dummies.columns = ['black_female','black_male',\n",
    "                   'hispan_female','hispan_male',\n",
    "                   'white_female','white_male']\n",
    "df[dummies.columns] = dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [5 points] Rename the previously 6 newly created dummy variables accordingly, i.e., `black_male` equals 1 for a black male applicant and 0 otherwise, `white_female` equals 1 for a white female applicant and 0 otherwise, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns have been properly named above in part 1. during their creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You are interested in building a model that accurately predict loan rejection (`rejection`) based on various applicants' features such as `loanamt`, `appinc`, `unit`, `married`, `dep`, `emp`, `yjob`, `self`, `atotinc`, `cototinc`, `hexp`, `price`, `other`, `liq`, `rep`, `gdlin`, `lines`, `mortg`, `cons`, `pubrec`, `hrat`, `obrat`, `fixadj`, `term`, `apr`, `gift`, `cosign`, `netw`, `uem`, `min30`, `bd`, `mi`, `old`, `vr`, `sch`, `mortno`, `chist`, `multi`, `loanprc`, `thick`, and 5 of the 6 newly created race-gender dummies, i.e., make the `white_male` the base category.\n",
    "    1. [5 points] Replace *all* the proposed features measured in USD with their natural logarithm provided their values are strictly positive. If they are zero instead, then leave them as such.\n",
    "    2. [5 points] *Add* demeaned squared terms of *all* features measured in units of time to your data frame, e.g., `lemp2` where $\\texttt{lemp2}=(\\ln(\\texttt{emp})-\\overline{ln(\\texttt{emp}})^2$ where $\\overline{ln(\\texttt{emp}}$ represents the sample average of the `lemp2` variable. **Note**: You do not need to do this for the remaining features that are not measured in units of time.\n",
    "    3. [10 points] *Add* to your data frame _all_ products between the 5 race-gender dummy variables and the other **non-dummy** features in the data frame so far (including those you created in point B. above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting data set and setting white_male to be base category\n",
    "df = df[['reject','loanamt','appinc','unit','married','dep','emp','yjob','self','atotinc','cototinc','hexp','price','other',\n",
    "          'liq','rep','gdlin','lines','mortg','cons','pubrec','hrat','obrat','fixadj','term','apr','gift','cosign','netw','unem',\n",
    "          'min30','bd','mi','old','vr','sch','mortno','chist','multi','loanprc','thick','black_female','black_male',\n",
    "          'hispan_female','hispan_male','white_female']]\n",
    "\n",
    "#Part A: Replacing features in USD with natural log of values\n",
    "usd = ['loanamt','appinc','atotinc','cototinc','hexp','price','other','liq','netw','apr']\n",
    "df[usd] = df[usd].where(df <= 0, np.log(df))\n",
    "\n",
    "#Part B: adding demeaned squared terms to all features in units of time\n",
    "time = ['emp','yjob','term']\n",
    "time2 = [var + '2' for var in time]\n",
    "df[time2] = df[time].sub(df[time].mean()) ** 2\n",
    "\n",
    "#Part C:\n",
    "#Creating demeaned variables\n",
    "tmp = df.columns[1:]\n",
    "demeaned = []\n",
    "for x in tmp:\n",
    "    df[x + '_dmean'] = df[x] - df[x].mean()\n",
    "    demeaned.append(x + '_dmean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating interacted features\n",
    "dumvars = [x + '_dmean' for x in list(dummies)][:-1]\n",
    "for dum in dumvars:\n",
    "    for var in demeaned:\n",
    "        df[dum + ':' + var] = df[dum] * df[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating design matrices\n",
    "f = 'reject ~ -1 +' + '+'.join(df.columns[1:].difference(demeaned, sort = False))\n",
    "y, X = patsy.dmatrices(f, data = df, return_type = 'dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Standard Scaler Object\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "#Create standardized X\n",
    "X_st = pd.DataFrame(sc.fit_transform(X), columns = X.columns)\n",
    "\n",
    "#Create train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xst_train, Xst_test, y_train, y_test = train_test_split(X_st, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Create K-Fold Cross Validation Object\n",
    "from sklearn.model_selection import KFold\n",
    "fold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "#Data Frame to store scores\n",
    "scores = pd.DataFrame(columns = ['score', 'b_score','num_regs','b_regs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [20 points] Perform a __Ridge__ Logistic Regression of your model and choose the necessary hyperparameter via a 5-fold cross-validation. Report your logistic score and the confusion matrix based on a validation test made up of 20% of the original sample (use 42 as the seed). **Note**: You can do this via the `LogisticRegressionCV` function from the `sklearn.linear_model` subpackage by choosing a suitable set for the `Cs` and `l1_ratios` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.3059322] \n",
      "\n",
      "0.8258426966292135 \n",
      "\n",
      "[[289  30]\n",
      " [ 32   5]]\n"
     ]
    }
   ],
   "source": [
    "RidgeCV = LogisticRegressionCV(\n",
    "    Cs=list(np.linspace(0.01,20,60,endpoint=True)) #this corresponds to 1/lambda above\n",
    "    ,penalty='l2'\n",
    "    ,scoring='accuracy' #proportion of main diag of confusion matrix\n",
    "    ,cv=fold\n",
    "    ,random_state=42\n",
    "    ,max_iter=10000\n",
    "    ,fit_intercept=True\n",
    "    ,solver='saga' \n",
    "    ,tol=10\n",
    ")\n",
    "RLogit_cv = RidgeCV.fit(Xst_train, y_train.values.ravel())\n",
    "\n",
    "print(RLogit_cv.C_,'\\n')\n",
    "print(RLogit_cv.score(Xst_test, y_test),'\\n')\n",
    "scores.loc['Ridge','score'] = RLogit_cv.score(Xst_test, y_test)\n",
    "print(confusion_matrix(y_test, RLogit_cv.predict(Xst_test)))\n",
    "scores.loc['Ridge','num_regs'] = pd.DataFrame(RLogit_cv.coef_).any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that we have a very imbalanced data set. As such, we consider an alternative scoring method using the \"balanced_accuracy\" scorer. This method is designed to handle unbalanced data sets and is defined as the average of recall based on each class of the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1553\n",
       "1.0     225\n",
       "Name: reject, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001] \n",
      "\n",
      "0.5646022197746337 \n",
      "\n",
      "[[274  45]\n",
      " [ 27  10]]\n"
     ]
    }
   ],
   "source": [
    "RidgeCV = LogisticRegressionCV(\n",
    "    Cs=list(np.linspace(0.001,10,60,endpoint=True)) #this corresponds to 1/lambda above\n",
    "    ,penalty='l2'\n",
    "    ,scoring='balanced_accuracy' #proportion of main diag of confusion matrix\n",
    "    ,cv=fold\n",
    "    ,random_state=42\n",
    "    ,max_iter=10000\n",
    "    ,fit_intercept=True\n",
    "    ,solver='saga' \n",
    "    ,tol=10\n",
    ")\n",
    "RLogit_cv = RidgeCV.fit(Xst_train, y_train.values.ravel())\n",
    "\n",
    "print(RLogit_cv.C_,'\\n')\n",
    "print(RLogit_cv.score(Xst_test, y_test),'\\n')\n",
    "scores.loc['Ridge','b_score'] = RLogit_cv.score(Xst_test, y_test)\n",
    "print(confusion_matrix(y_test, RLogit_cv.predict(Xst_test)))\n",
    "scores.loc['Ridge','b_regs'] = pd.DataFrame(RLogit_cv.coef_).any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [20 points] Perform a __Lasso__ Logistic Regression of your model and choose the necessary hyperparameter via a 5-fold cross-validation. Report your logistic score and the confusion matrix based on a validation test made up of 20% of the original sample (use 42 as the seed). **Note:** You can do this via the `LogisticRegressionCV` function from the `sklearn.linear_model` subpackage by choosing a suitable set for the `Cs` and `l1_ratios` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001] \n",
      "\n",
      "0.8960674157303371 \n",
      "\n",
      "[[319   0]\n",
      " [ 37   0]]\n"
     ]
    }
   ],
   "source": [
    "LassoCV = LogisticRegressionCV(\n",
    "    Cs=list(np.linspace(0.001,10,20,endpoint=True)) #this corresponds to 1/lambda above\n",
    "    ,penalty='l1'\n",
    "    ,scoring='accuracy' #proportion of main diag of confusion matrix\n",
    "    ,cv=fold\n",
    "    ,random_state=42\n",
    "    ,max_iter=10000\n",
    "    ,fit_intercept=True\n",
    "    ,solver='saga' \n",
    "    ,tol=10\n",
    ")\n",
    "LLogit_cv = LassoCV.fit(Xst_train, y_train.values.ravel())\n",
    "\n",
    "print(LLogit_cv.C_,'\\n')\n",
    "print(LLogit_cv.score(Xst_test, y_test),'\\n')\n",
    "scores.loc['Lasso','score'] = LLogit_cv.score(Xst_test, y_test)\n",
    "print(confusion_matrix(y_test, LLogit_cv.predict(Xst_test)))\n",
    "scores.loc['Lasso','num_regs'] = pd.DataFrame(LLogit_cv.coef_).any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18461224] \n",
      "\n",
      "0.5636278912140981 \n",
      "\n",
      "[[282  37]\n",
      " [ 28   9]]\n"
     ]
    }
   ],
   "source": [
    "LassoCV = LogisticRegressionCV(\n",
    "    Cs=list(np.linspace(0.001,3,50,endpoint=True))\n",
    "    ,penalty='l1'\n",
    "    ,scoring='balanced_accuracy' #proportion of main diag of confusion matrix\n",
    "    ,cv=fold\n",
    "    ,random_state=42\n",
    "    ,max_iter=10000\n",
    "    ,fit_intercept=True\n",
    "    ,solver='saga' \n",
    "    ,tol=10\n",
    ")\n",
    "LLogit_cv = LassoCV.fit(Xst_train, y_train.values.ravel())\n",
    "\n",
    "print(LLogit_cv.C_,'\\n')\n",
    "print(LLogit_cv.score(Xst_test, y_test),'\\n')\n",
    "scores.loc['Lasso','b_score'] = LLogit_cv.score(Xst_test, y_test)\n",
    "print(confusion_matrix(y_test, LLogit_cv.predict(Xst_test)))\n",
    "scores.loc['Lasso','b_regs'] = pd.DataFrame(LLogit_cv.coef_).any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. [20 points] Perform an __Elastic Net__ Logistic Regression of your model and choose the necessary hyperparameter via a 5-fold cross-validation. Report your logistic score and the confusion matrix based on a validation test made up of 20% of the original sample (use 42 as the seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001] \n",
      "\n",
      "[0.1] \n",
      "\n",
      "0.851123595505618 \n",
      "\n",
      "[[300  19]\n",
      " [ 34   3]]\n"
     ]
    }
   ],
   "source": [
    "ElastCV = LogisticRegressionCV(\n",
    "    Cs=list(np.linspace(0.001,10,30,endpoint=True))\n",
    "    ,penalty='elasticnet'\n",
    "    ,l1_ratios=np.linspace(0.1,0.9,5,endpoint=True) \n",
    "    ,scoring='accuracy' #proportion of main diag of confusion matrix\n",
    "    ,cv=fold\n",
    "    ,random_state=42\n",
    "    ,max_iter=10000\n",
    "    ,fit_intercept=True\n",
    "    ,solver='saga' \n",
    "    ,tol=10\n",
    ")\n",
    "\n",
    "ELogit_cv = ElastCV.fit(Xst_train, y_train.values.ravel())\n",
    "\n",
    "print(ELogit_cv.C_,'\\n')\n",
    "print(ELogit_cv.l1_ratio_,'\\n')\n",
    "print(ELogit_cv.score(Xst_test, y_test),'\\n')\n",
    "scores.loc['Elastic Net','score'] = ELogit_cv.score(Xst_test, y_test)\n",
    "print(confusion_matrix(y_test, ELogit_cv.predict(Xst_test)))\n",
    "scores.loc['Elastic Net','num_regs'] = pd.DataFrame(ELogit_cv.coef_).any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for the above regression, we could lower the Cs to 0.0001 to increase the score. However, this result will be effectively identical to the Lasso Logistic Regression above. More explanation on this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10353793] \n",
      "\n",
      "[0.36666667] \n",
      "\n",
      "0.5604930949758536 \n",
      "\n",
      "[[280  39]\n",
      " [ 28   9]]\n"
     ]
    }
   ],
   "source": [
    "ElastCV = LogisticRegressionCV(\n",
    "    Cs=list(np.linspace(0.0001,1,30,endpoint=True))\n",
    "    ,penalty='elasticnet'\n",
    "    ,l1_ratios=np.linspace(0.1,0.9,10,endpoint=True) \n",
    "    ,scoring='balanced_accuracy'\n",
    "    ,cv=fold\n",
    "    ,random_state=42\n",
    "    ,max_iter=10000\n",
    "    ,fit_intercept=True\n",
    "    ,solver='saga' \n",
    "    ,tol=10\n",
    ")\n",
    "\n",
    "ELogit_cv = ElastCV.fit(Xst_train, y_train.values.ravel())\n",
    "\n",
    "print(ELogit_cv.C_,'\\n')\n",
    "print(ELogit_cv.l1_ratio_,'\\n')\n",
    "print(ELogit_cv.score(Xst_test, y_test),'\\n')\n",
    "scores.loc['Elastic Net','b_score'] = ELogit_cv.score(Xst_test, y_test)\n",
    "print(confusion_matrix(y_test, ELogit_cv.predict(Xst_test)))\n",
    "scores.loc['Elastic Net','b_regs'] = pd.DataFrame(ELogit_cv.coef_).any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [10 points] What machine among the three you built would you use and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the scores for the various machines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>b_score</th>\n",
       "      <th>num_regs</th>\n",
       "      <th>b_regs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.564602</td>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.896067</td>\n",
       "      <td>0.563628</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elastic Net</th>\n",
       "      <td>0.851124</td>\n",
       "      <td>0.560493</td>\n",
       "      <td>152</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                score   b_score num_regs b_regs\n",
       "Ridge        0.825843  0.564602      278    278\n",
       "Lasso        0.896067  0.563628        0    278\n",
       "Elastic Net  0.851124  0.560493      152    278"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the scores of the various machines, we also note that the Lasso Logistic Regression has the highest score (i.e. best prediction power) when judged based on pure accuracy. However, the Lasso Logistic Regression selects 0 regressors. This is due to the fact that our data is very imbalanced. Looking above at the confusion matrices, we note that this machine never predicts any rejections which produces its high score. A similar result would be seen with the Elastic Net if we were to allow the C value to go lower. As such, it is questionable whether the score based on accuracy alone can be trusted given the imbalance in our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That conclusion brings us to consider the balanced_score method. While this method may decrease the accuracy of the model, the score itself may be considered for the sake of thoroughness. In this instance, the Ridge Regression has the highest balanced_score. The Lasso Regression follows this and is followed by the Elastic Net. However, the differences among all of these machines are fairly small. It is also important to note that all models select all 278 regressors in the balanced accuracy comparison. As such, while worth the consideration, balanced_score did not provide much argument in favor of any regression. Thus, we will still focus on the pure accuracy score models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose again that the motivation behind the machine is to find one with powerful prediction power while selecting the optimal and ideally more parsimonious model. Given these above considerations, we propose that the __*Elastic Net*__ is the best machine for prediction for several reasons. With proper limiting to the C value and selection of l1_ratio, the Elastic Net provides a good balance betweent he Ridge and Lasso. This is evident in both its pure accuracy score and the number of regressors it selects. Importantly, it helps select fewer regressors than the Ridge, one of the goals behind our machine, while maintaining higher prediction power. The Elastic Net machine also produces a model that still predicts some outcomes to be rejections while selecting regressors, two key failures of the Lasso machine. As such, the Elastic Net is the optimal machine to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
